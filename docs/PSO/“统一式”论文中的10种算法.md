# “统一式”论文中的10中算法

部分资料来自于ChatGPT

| 算法名称          | 算法介绍（摘自提出论文或资料）                               |
| ----------------- | ------------------------------------------------------------ |
| 1.SPSO-SIS        | Bratton D, Kennedy J. Defining a standard for particle swarm optimization. In: Proceedings of the IEEE Swarm Intelligence Symposium, Honolulu, 2007. 120–127<br />文中虽然定义了SPSO，但是并不是“新提出”的方式，而是通过对初代PSO以及两种PSO的变形进行详述和对比之后，从实验结果出发（测试多种基准函数），总结出标准PSO算法所应该包含的几个要素，并以此作为一种基线，供后来的研究者们使用。 |
| 2.Cooperative PSO | van den Bergh F, Engelbrecht A P. A cooperative approach to particle swarm optimization. IEEE Trans Evol Comput, 2004, 3: 225–239<br />将粒子的D维分到D个粒子群中，每个粒子群优化一维向量，评价适应度时将这些分量合并为一个完整的向量。例如第i个粒子群，除第i个分量外，其他D-1个分量都设为最优值，不断用第i个粒子群中的粒子替换第i个分量，直到得到第i维的最优值，其他维相同。为将有联系的分量划分在一个群，可将D维向量分配到m个粒子群优化，则前D mod m个粒子群的维数是D/m的向上取整。后m－(Dmod m)个粒子群的维数是D/m的向下取整。协同PSO在某些问题上有更快的收敛速度，但该算法容易被欺骗。 |
| 3.PSO-GFES        | Hu J, Wang Z, Qiao S, et al. The fitness evaluation strategy in particle swarm optimization. Appl Math Comput, 2011, 21: 8655–8670 |
| 4.FIPSO           | Mendes R, Kennedy J, Neves J. The fully informed particle swarm: simpler, maybe better. IEEE Trans Evol Comput, 2004, 3: 204–210一个粒子被领域内的每一个粒子吸引。<br />在 FIPS 中，每个粒子都保持两组最佳位置：它自己的最佳位置和它每个邻居的最佳位置。个人最佳位置是粒子在自己的搜索历史中找到的最佳位置，而邻居最佳位置是粒子的任何邻居找到的最佳位置。每个粒子根据这两组最佳位置以及群体中任何粒子找到的全局最佳位置更新其速度和位置。通过保持个人和邻居的最佳位置，FIPS 允许每个粒子获得更多关于搜索空间的信息，并就其移动做出更明智的决定。<br />与原始 PSO 算法相比，这可以改进收敛性并更好地探索搜索空间。然而，信息量的增加也使 FIPS 的计算成本更高，并且可能需要更多的内存来存储额外的最佳位置集。FIPS的速度更新公式与PSO存在一些差异：FIPS 中的速度更新方程包括三个由不同加速度常数加权的项，而 PSO 中的速度更新方程仅包括两个由相同加速度常数加权的项。<br />在 FIPS 中，第三项对应于群体中任何粒子找到的全局最佳位置，而在 PSO 中，全局最佳位置包含在第二项中。这允许 FIPS 在更新粒子速度时考虑更多的全局信息，从而可以改进收敛性并更好地探索搜索空间。FIPS 中的位置更新方程与 PSO 中的相同，它只是将更新后的速度与粒子的当前位置相加以获得其新位置。然而，由于 FIPS 保持个人和邻居的最佳位置，因此 FIPS 中的更新速度可能与 PSO 中的更新速度不同，PSO 仅考虑每个粒子的个人最佳位置和群体中任何粒子找到的全局最佳位置。 |
| 5.CLPSO           | Liang J J, Qin A K, Suganthan P N, et al. Comprehensive learning particle swarm optimizer for global optimization of multimodal functions. IEEE Trans Evol Comput, 2006, 3: 281–295。<br />CLPSO与PSO的差别主要是原来的PSO需要利用p-best和g-best，而对于CLPSO来说更新位置只需要p-best。而且对于PSO，p-best的更新只需要自己的p-best，CLPSO的更新中p-best可以来自于其他个体。此外CLPSO存在这一种所谓的aging策略，即m次没有得到最优解，再进行重新赋值。同时惯性变量在整个过程中也随着迭代次数增多线性减少。 |
| 6.OLPSO           | Zhan Z H, Zhang J, Li Y, et al. Orthogonal learning particle swarm optimization. IEEE Trans Evol Comput, 2011, 6: 832–847<br />OLPSO 的目标是通过增加群体的多样性并使其更有效地探索搜索空间来提高 PSO 算法的收敛速度和搜索性能。OLPSO的主要思想是将群体分为几个子群，每个子群体搜索整个空间的不同子空间，且每个子群都用不同的随机种子进行初始化，子群内的粒子相互通信以共享信息并更新它们的位置和速度。使用正交学习可以促进每个子群内的通信，这是一种有助于识别数据的重要特征并减少它们之间的冗余。<br />空间被划分为多个子空间后，每个粒子根据其在搜索空间中的位置被分配到一个特定的子空间，每个子空间内的粒子相互通信以共享信息并更新它们的位置和速度。OLPSO中的认知和社会加速常数会根据粒子在子群中的位置进行调整，对于位于子空间中心附近的粒子，加速度因子通常被设为更高的值，有助于使粒子更深入地在空间中进行探索；相反，位于子空间边界附近的粒子具有较低的加速度因子，以能够更有效地探索相邻地子空间。<br />OLPSO中每个粒子的速度使用同一子空间内相邻粒子的信息进行更新，这使粒子能够合作并避免搜索中的冗余，从而更有效地探索搜索空间。（OLPSO中的更新公式和PSO中的更新公式应该是一致的，只是更新策略有不同）<br />【正交(ChatGPT)】：在数学中，“正交”是指向量或函数彼此垂直的性质。如果两个向量的点积为零，则称它们是正交的。<br />【在优化算法中，“正交”指的是一种将搜索空间划分为子空间的技术】，每个子空间都垂直于所有其他子空间。这种方法用于促进多样性并减少种群中的冗余，从而提高探索和开发能力。粒子根据它们的位置进行聚类，每个聚类被分配到一个特定的子空间。子空间被定义为由簇内粒子位置之间的差异形成的向量的跨度。子空间与其他簇的子空间正交，这意味着它垂直于所有其他子空间。<br />【在正交学习粒子群优化 (OLPSO) 中】，群被划分为多个正交子空间，每个粒子根据其在搜索空间中的位置被分配到特定的子空间。这种方法的目标是通过促进多样性和减少冗余来提高群体的探索和利用能力。<br /> OLPSO 中的正交群基于正交学习技术调整其方向和大小，以确保子空间保持相互垂直并保持其多样性。 |
| 7.BBPSO           | Kennedy J. Bare bones particle swarms. In: Proceedings of the IEEE Swarm Intelligence Symposium, Indianapolis, 2003. 80–87<br />一种不包含“参数”的PSO，文中多次提到高斯分布给算法带来的优势（相对于其他两种算法），多次阅读本文但是并未搞清楚算法思想，全文冗余的内容太多，阅读困难。 |
| 8.SPSO-2007       | 没有找到具体参考文献，推测可能是SPSO-SIS的类似变形           |
| 9.MLPSO           | Wang L, Yang B, Chen Y. Improving particle swarm optimization using multi-layer searching strategy. Inf Sci, 2014, 274: 70–94<br />（传统粒子群优化算法由两个搜索层和一个群体构成，分别是个体最优解搜索层、全局最优解搜索层、粒子种群，这里还有另外一种阐述：粒子通过追踪两个向量来更新自己：粒子本身找到的最佳解决方案pbest和种群找到的最佳解决方案gbest。因为从本质上讲，速度和位置都是向量。）<br />粒子群优化 (PSO) 和多层粒子群优化 (MLPSO) 之间的主要区别是【MLPSO 在多层粒度上运行】，而【PSO 在单层上运行】。在PSO中，粒子根据它们的个人最佳位置和全局最佳位置在搜索空间中移动，这些位置在每次迭代中更新。<br />PSO中粒子的运动由一组方程式控制，这些方程式根据粒子的当前位置、个人最佳位置和全局最佳位置计算粒子的速度。MLPSO 在多层粒度上运行，每一层代表不同的抽象级别或粒度，粒子穿过这些层以探索搜索空间。<br />【每层中粒子的运动仍然由 PSO 中使用的同一组方程控制】，但【每层中的粒子具有不同的个人最佳位置和全局最佳位置】。在 MLPSO 中，每一层中的粒子都基于在上一层中找到的最佳位置移动。这允许算法同时在多个层中搜索解决方案，避免陷入局部最优。 |
| 10.QPSO           | （1）Sun J, Feng B, Xu W. Particle swarm optimization with particles having quantum behavior. In: Proceedings of IEEE Congress on Evolutionary Computation, Portland, 2004. 1571–1580（2）Sun J, Fang W, Palade V, et al. Quantum-behaved particle swarm optimization with Gaussian distributed local attractor point. Appl Math Comput, 2011, 7: 3763–3775<br />因为粒子的位置和速度在量子空间中不能一起确定，所以用【波函数】表示粒子位置（在量子空间中只有位置没有速度），通过【蒙特卡罗方法】求出粒子位置。gbest求解通过mbest（即所有pbest的平均值）得到。mbest是所有个体平均最优，通过它来求解粒子出现在相对点的位置，用L表示。而粒子的势表示位置的最终值，与L直接相关。 <br />QPSO要设置的参数较少:　没有PSO中的(惯性因子w, 局部学习因子c1和全局学习因子c2), QPSO中只有一个创新参数alpha(一般不大于1) |